{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(fn):\n",
    "  with open(fn) as fd:\n",
    "    data = np.array([\n",
    "          [\n",
    "            float(i) for i in line.split(',')\n",
    "          ] \n",
    "          for line in fd.read().split('\\n') if line!='']\n",
    "        )\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(tn, tl):\n",
    "    train_data = read_csv(tn)\n",
    "    train_labels = read_csv(tl)\n",
    "    return train_data, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b985b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy():\n",
    "    def loss(self, y, y_hat):\n",
    "        n = len(y)\n",
    "        lp = - np.log(y_hat[np.arange(n), y.argmax(axis=1)])\n",
    "        return np.sum(lp)/n\n",
    "        \n",
    "    def grad(self, y, y_hat):\n",
    "        n = y.shape[0]\n",
    "        res = y_hat - y\n",
    "        return res/n\n",
    "\n",
    "class Sigmoid():\n",
    "  def __init__(self):\n",
    "    self.name = 'sigmoid'\n",
    "    \n",
    "  def act(self, inp):  \n",
    "    return 1 / (1 + np.exp(-inp))\n",
    "  \n",
    "  def grad(self, inp):\n",
    "    return inp * (1 - inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxActivation():\n",
    "    def __init__(self):\n",
    "        self.name = 'softmax'\n",
    "        \n",
    "    def act(self, inp):\n",
    "        e = np.exp(inp - np.max(inp, axis=1, keepdims=True))\n",
    "        return e / np.sum(e, axis=1, keepdims=True)\n",
    "\n",
    "    def prime(self, inp):\n",
    "        return inp * (1 - inp)\n",
    "        \n",
    "activations = {\n",
    "    'sigmoid': Sigmoid,\n",
    "    'softmax': SoftmaxActivation\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d587304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer():\n",
    "  def __init__(self, input_dims, op_dims, activation):\n",
    "    self.w = np.random.rand(input_dims, op_dims) \n",
    "    self.b = np.zeros((1, op_dims))\n",
    "    self.act = activations[activation]()\n",
    "    \n",
    "\n",
    "  def fp(self, inp):\n",
    "    self.inp = inp\n",
    "    self.op = np.dot(self.inp, self.w) + self.b\n",
    "    self.op = self.act.act(self.op)\n",
    "    return self.op\n",
    "\n",
    "  def bp(self, oe, lr):\n",
    "    if self.act.name != 'softmax':\n",
    "        oe = self.act.grad(self.op) * oe\n",
    "    \n",
    "    ie = np.dot(oe, self.w.T)\n",
    "    we = np.dot(self.inp.T, oe)\n",
    "    self.w -= lr * we\n",
    "\n",
    "    if self.act.name == 'softmax':\n",
    "        self.b -= lr * np.sum(oe, axis=0, keepdims=True)\n",
    "    else:\n",
    "        self.b -= lr * np.sum(oe, axis=0)\n",
    "    return ie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c05d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "  def __init__(self):\n",
    "    self._los_ = None\n",
    "    self.ls = []\n",
    "\n",
    "  def add(self, layer):\n",
    "    self.ls.append(layer)\n",
    "\n",
    "  def loss(self, l):\n",
    "    self._los_ = l\n",
    "\n",
    "  def predict(self, inp):\n",
    "    op = inp\n",
    "    for layer in self.ls:\n",
    "        op = layer.fp(op)\n",
    "    return op\n",
    "  \n",
    "  def train(self, x, y, epcs, \n",
    "                          lr, bs=200):\n",
    "    N = len(x)\n",
    "    history = []\n",
    "    for ep in range(epcs):\n",
    "      err = 0\n",
    "      for j in range(int(N/bs)):\n",
    "        op = self.predict(\n",
    "              x[j:j+bs]\n",
    "            )\n",
    "        err += self._los_.loss(y[j:j+bs], op)\n",
    "\n",
    "        __err__ = self._los_.grad(y[j:j+bs], op)\n",
    "        for l in reversed(self.ls):\n",
    "            __err__ = l.bp(__err__, lr)\n",
    "\n",
    "      if ep%100 == 0:\n",
    "        print(\"Epoch {}/{}  error={}\".format(ep+1, epcs, err))\n",
    "      if err < 0.03:\n",
    "        break\n",
    "      history.append({\n",
    "          'epoch': ep,\n",
    "          'err': err\n",
    "      })\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ce065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change file names here to test on different files.\n",
    "tdn = 'gaussian_train_data.csv'\n",
    "tln = 'gaussian_train_label.csv'\n",
    "test_data_name = 'gaussian_test_data.csv'\n",
    "test_label_name = 'gaussian_test_label.csv'\n",
    "train_x, train_y = read_data(tdn, tln)\n",
    "test_x, test_y = read_data(test_data_name, test_label_name)\n",
    "\n",
    "\n",
    "a = train_y.astype(int).flatten()\n",
    "train_y = np.zeros((a.size, a.max() + 1))\n",
    "train_y[np.arange(a.size), a] = 1\n",
    "\n",
    "net = Model()\n",
    "\n",
    "net.add(FullyConnectedLayer(2, 128, 'sigmoid'))\n",
    "net.add(FullyConnectedLayer(128, 128, 'sigmoid'))\n",
    "net.add(FullyConnectedLayer(128, 2, 'softmax'))\n",
    "net.loss(CrossEntropy())\n",
    "\n",
    "hist = net.train(train_x, train_y, epcs=8000, lr=0.7)\n",
    "\n",
    "preds = net.predict(test_x).argmax(axis=1)\n",
    "preds_train = net.predict(train_x).argmax(axis=1)\n",
    "print (\"Train accuracy: \", accuracy_score(preds_train, a))\n",
    "print (\"Test accuracy: \", accuracy_score(preds, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
